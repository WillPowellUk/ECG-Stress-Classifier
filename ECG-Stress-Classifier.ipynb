{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Classifier\n",
    "## Overview\n",
    "* Data Extraction: Downloads and sorts through database\n",
    "* Signal processing: \n",
    "    + Pre-processing - filtering and signal cleaning\n",
    "    + Feature Extraction - PQRST peak extraction\n",
    "    + Feature Addition - Adding new features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and Globals\n",
    "Modify settings to select database, model etc. and tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SETTINGS\n",
    "\n",
    "# Select Database:\n",
    "database = \"Spider\" # database = \"BrainPatch\"\n",
    "\n",
    "# GLOBALS\n",
    "if database == 'Spider':\n",
    "    sampling_rate = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import os\n",
    "import subprocess\n",
    "import Utilities\n",
    "import importlib\n",
    "importlib.reload(Utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataExtraction class\n",
    "class DataExtraction():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # Extract data and store to file named Data\n",
    "    def download_data(self):\n",
    "        if database == 'Spider':\n",
    "            directory = 'Data/Spider'\n",
    "            url = 'https://physionet.org/files/ecg-spider-clip/1.0.0/'\n",
    "            if not os.path.isdir(directory):\n",
    "                print(\"Downloading database...this may take a while\")\n",
    "                os.makedirs(directory)\n",
    "                cmd = f\"wget -r -N -c -np -P {directory} {url}\"\n",
    "                print(cmd)\n",
    "                try:\n",
    "                    subprocess.run(cmd)\n",
    "                except:\n",
    "                    print(\"Error: Unable to download database\")\n",
    "                    os.rmdir(directory)\n",
    "            else:\n",
    "                print(\"Using pre-downloaded database\")\n",
    "    \n",
    "    # sorts data into a single dataframe for each participant into a collective dataframe list\n",
    "    def sort_data(self):\n",
    "        print(\"Sorting data...\")\n",
    "\n",
    "        # try loading existing df if available\n",
    "        file_path = 'Data/StoredDataFrames/sorted_data.pkl'\n",
    "        ECG_df = Utilities.load_dataframe(file_path)\n",
    "        if ECG_df:\n",
    "            return ECG_df\n",
    "        \n",
    "        # otherwise create dataframe from scratch\n",
    "        ECG_df = []\n",
    "\n",
    "        if database == 'Spider':\n",
    "            database_directory = 'Data/Spider/physionet.org/files/ecg-spider-clip/1.0.0/'\n",
    "            # Exclude VP70 because of noise\n",
    "            sub_directories = ['VP02', 'VP03','VP05','VP06','VP08','VP09','VP11','VP12','VP14','VP15','VP17','VP18','VP20','VP23','VP24','VP26','VP27',\n",
    "                    'VP29','VP30','VP32','VP33','VP35','VP36','VP38','VP39','VP41','VP42','VP44','VP45','VP47','VP48','VP50','VP51','VP53',\n",
    "                    'VP54','VP56','VP57','VP59','VP61','VP62','VP63','VP64','VP65','VP66','VP68','VP69','VP71','VP72','VP73','VP74',\n",
    "                    'VP75','VP76','VP77','VP78','VP79','VP80']\n",
    "            for index, sub in enumerate(sub_directories):\n",
    "                # set path\n",
    "                ECG_file = f'{database_directory}{sub}/BitalinoECG.txt'\n",
    "                triggers_file = f'{database_directory}{sub}/Triggers.txt'\n",
    "\n",
    "                # append data to dataframe\n",
    "                ECG_participant_df = pd.read_csv(ECG_file, sep='\\t', names = ['ECG','time','NA'], engine='python')\n",
    "                ECG_participant_df = ECG_participant_df.drop(columns=['NA'])\n",
    "                \n",
    "                # set the start time to use to normalize the other times\n",
    "                normalized_time = ECG_participant_df.iloc[0,1]\n",
    "                ECG_participant_df.time = ECG_participant_df.time-normalized_time\n",
    "\n",
    "                # read in trigger file\n",
    "                triggers_df_temp = pd.read_csv(triggers_file, sep='\\t', names = ['clip','on','off'], engine='python')\n",
    "                triggers_df_temp.on = triggers_df_temp.on-normalized_time\n",
    "                triggers_df_temp.off = triggers_df_temp.off-normalized_time\n",
    "\n",
    "                # Create the 'Stressed' (label) column with all zeros\n",
    "                ECG_participant_df[\"Stressed\"] = np.zeros(len(ECG_participant_df))\n",
    "                # This checks which time stamps fall into the time ranges when the clips are delivered, results in a column of \"true\" and \"false\"\n",
    "                conditions = pd.concat([(ECG_participant_df['time'] >= triggers_df_temp.on[i]) & (ECG_participant_df['time'] <= triggers_df_temp.off[i]) for i in range(0,17)],axis=1).any(axis=1)\n",
    "                ECG_participant_df[\"Stressed\"] = conditions\n",
    "\n",
    "                # append data to complete df dictionary\n",
    "                ECG_df.append(ECG_participant_df)\n",
    "\n",
    "                Utilities.progress_bar(index, len(sub_directories)-1)\n",
    "\n",
    "        # save dataframe for nextime and return\n",
    "        Utilities.save_dataframe(ECG_df, file_path)\n",
    "        return ECG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SignalProcessing Class\n",
    "\n",
    "# Using Neurokit2 - using method 'neurokit' (5th order Butterworth filter) but can be changed to other cleaning method\n",
    "# Documentation can be found here: https://neuropsychology.github.io/NeuroKit/functions/ecg.html                      \n",
    "class SignalProcessing():\n",
    "    def __init__(self, ECG_df):\n",
    "        self.ECG_df = ECG_df\n",
    "\n",
    "    def clean(self):\n",
    "        print('Cleaning data...')\n",
    "        # try loading existing df if available\n",
    "        file_path = 'Data/StoredDataFrames/cleaned_data.pkl'\n",
    "        ECG_df = Utilities.load_dataframe(file_path)\n",
    "        if ECG_df:\n",
    "            self.ECG_df = ECG_df\n",
    "            return self.ECG_df\n",
    "        \n",
    "        # otherwise, create df from scratch, overwriting ECG_df with cleaned version \n",
    "        ECG_df = []\n",
    "        for index, ECG_particpant_df in enumerate(self.ECG_df):\n",
    "            ECG_df.append(nk.ecg_process(ECG_particpant_df['ECG'], sampling_rate, method='neurokit'))\n",
    "            Utilities.progress_bar(index, len(self.ECG_df)-1)\n",
    "        self.ECG_df = ECG_df\n",
    "        \n",
    "        # save dataframe for nextime\n",
    "        Utilities.save_dataframe(self.ECG_df, file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Pre-processing\n",
    "* Downloads data, normalizes timeframe and puts data into a dataframe dictionary of all partcipant data - `ECG_df`.\n",
    "* Cleans data using \n",
    "\n",
    "This will take a while if you haven't previously ran this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and sort data to create dataframe\n",
    "de = DataExtraction()\n",
    "de.download_data()\n",
    "ECG_df = de.sort_data()\n",
    "\n",
    "# Pass dataframe to be signal processed\n",
    "sp = SignalProcessing(ECG_df)\n",
    "sp.clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
